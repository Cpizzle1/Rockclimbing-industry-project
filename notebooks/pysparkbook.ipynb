{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "expected-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark as ps\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col, explode\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "entire-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = (ps.sql.SparkSession.builder \n",
    "        .master(\"local[4]\") \n",
    "        .appName(\"wikiclimber\") \n",
    "        .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cellular-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/home/jovyan/work/Documents/dsi/8a_kaggle/dev_imac2/ascents_spark.csv\", header=True)\n",
    "# df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "purple-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"user_id\", df[\"user_id\"].cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "revised-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"rating\", df[\"rating\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "incident-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"date\", df[\"date\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "comparative-printing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------+------+---------+\n",
      "|_c0|                name|user_id|rating|     date|\n",
      "+---+--------------------+-------+------+---------+\n",
      "|  0|      The King And I|      1|     0|918342000|\n",
      "|  1|              vet ej|      1|     0|925509600|\n",
      "|  2|              Mr Big|      1|     0|933026400|\n",
      "|  3|       Tak ska du ha|      1|     0|933026400|\n",
      "|  4|       Korpen flyger|      1|     0|933458400|\n",
      "|  5|           Valentine|      1|     0|914022000|\n",
      "|  6|             Namnlös|      1|     0|915404400|\n",
      "|  7|Nuat Hin (Massage...|      1|     0|916268400|\n",
      "|  8|           Circus Oz|      1|     0|916441200|\n",
      "|  9|       Primal scream|      1|     0|917478000|\n",
      "| 10|     Fit to be Thaid|      1|     0|917650800|\n",
      "| 11|            Nylander|      1|     0|925423200|\n",
      "| 12|         Farmor Anka|      1|     0|925250400|\n",
      "| 13|              Vet ej|      1|     0|925509600|\n",
      "| 14|              Vet ej|      1|     0|925596000|\n",
      "| 15|              Vet ej|      1|     0|925596000|\n",
      "| 16|          Be Careful|      1|     0|913503600|\n",
      "| 17|         Monkey Love|      1|     0|913935600|\n",
      "| 18|      Short & Savage|      1|     0|914022000|\n",
      "| 19|        Captain Hook|      1|     0|914194800|\n",
      "+---+--------------------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "framed-traveler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', 'name', 'user_id', 'rating', 'date']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "filled-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(\"notes\",\"raw_notes\",\"total_score\",'year','last_year', 'rec_date','project_ascent_date', 'crag_id','sector_id','comment','description','yellow_id','climb_try','repeat',\n",
    "#        'exclude_from_ranking','user_recommended','chipped', 'shoe', 'video', 'screename').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "flexible-gazette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_collect_as_arrow',\n",
       " '_jcols',\n",
       " '_jdf',\n",
       " '_jmap',\n",
       " '_jseq',\n",
       " '_lazy_rdd',\n",
       " '_repr_html_',\n",
       " '_sc',\n",
       " '_schema',\n",
       " '_sort_cols',\n",
       " '_support_repr_html',\n",
       " '_to_corrected_pandas_type',\n",
       " 'agg',\n",
       " 'alias',\n",
       " 'approxQuantile',\n",
       " 'cache',\n",
       " 'checkpoint',\n",
       " 'coalesce',\n",
       " 'colRegex',\n",
       " 'collect',\n",
       " 'columns',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'createGlobalTempView',\n",
       " 'createOrReplaceGlobalTempView',\n",
       " 'createOrReplaceTempView',\n",
       " 'createTempView',\n",
       " 'crossJoin',\n",
       " 'crosstab',\n",
       " 'cube',\n",
       " 'describe',\n",
       " 'distinct',\n",
       " 'drop',\n",
       " 'dropDuplicates',\n",
       " 'drop_duplicates',\n",
       " 'dropna',\n",
       " 'dtypes',\n",
       " 'exceptAll',\n",
       " 'explain',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'foreach',\n",
       " 'foreachPartition',\n",
       " 'freqItems',\n",
       " 'groupBy',\n",
       " 'groupby',\n",
       " 'head',\n",
       " 'hint',\n",
       " 'intersect',\n",
       " 'intersectAll',\n",
       " 'isLocal',\n",
       " 'isStreaming',\n",
       " 'is_cached',\n",
       " 'join',\n",
       " 'limit',\n",
       " 'localCheckpoint',\n",
       " 'mapInPandas',\n",
       " 'na',\n",
       " 'orderBy',\n",
       " 'persist',\n",
       " 'printSchema',\n",
       " 'randomSplit',\n",
       " 'rdd',\n",
       " 'registerTempTable',\n",
       " 'repartition',\n",
       " 'repartitionByRange',\n",
       " 'replace',\n",
       " 'rollup',\n",
       " 'sample',\n",
       " 'sampleBy',\n",
       " 'schema',\n",
       " 'select',\n",
       " 'selectExpr',\n",
       " 'show',\n",
       " 'sort',\n",
       " 'sortWithinPartitions',\n",
       " 'sql_ctx',\n",
       " 'stat',\n",
       " 'storageLevel',\n",
       " 'subtract',\n",
       " 'summary',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'toDF',\n",
       " 'toJSON',\n",
       " 'toLocalIterator',\n",
       " 'toPandas',\n",
       " 'transform',\n",
       " 'union',\n",
       " 'unionAll',\n",
       " 'unionByName',\n",
       " 'unpersist',\n",
       " 'where',\n",
       " 'withColumn',\n",
       " 'withColumnRenamed',\n",
       " 'withWatermark',\n",
       " 'write',\n",
       " 'writeStream']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "hungry-century",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4111879"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prescribed-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "standard-pacific",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4111879"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "collective-cancer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------+------+---------+\n",
      "|_c0|                name|user_id|rating|     date|\n",
      "+---+--------------------+-------+------+---------+\n",
      "|  0|      The King And I|      1|     0|918342000|\n",
      "|  1|              vet ej|      1|     0|925509600|\n",
      "|  2|              Mr Big|      1|     0|933026400|\n",
      "|  3|       Tak ska du ha|      1|     0|933026400|\n",
      "|  4|       Korpen flyger|      1|     0|933458400|\n",
      "|  5|           Valentine|      1|     0|914022000|\n",
      "|  6|             Namnlös|      1|     0|915404400|\n",
      "|  7|Nuat Hin (Massage...|      1|     0|916268400|\n",
      "|  8|           Circus Oz|      1|     0|916441200|\n",
      "|  9|       Primal scream|      1|     0|917478000|\n",
      "| 10|     Fit to be Thaid|      1|     0|917650800|\n",
      "| 11|            Nylander|      1|     0|925423200|\n",
      "| 12|         Farmor Anka|      1|     0|925250400|\n",
      "| 13|              Vet ej|      1|     0|925509600|\n",
      "| 14|              Vet ej|      1|     0|925596000|\n",
      "| 15|              Vet ej|      1|     0|925596000|\n",
      "| 16|          Be Careful|      1|     0|913503600|\n",
      "| 17|         Monkey Love|      1|     0|913935600|\n",
      "| 18|      Short & Savage|      1|     0|914022000|\n",
      "| 19|        Captain Hook|      1|     0|914194800|\n",
      "+---+--------------------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "committed-jason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, name: string, user_id: int, rating: int, date: int]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "downtown-calculator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.364091652613869"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.createOrReplaceTempView('ratings')\n",
    "global_rating = spark.sql('''\n",
    "    SELECT AVG(rating) as global_mean\n",
    "    FROM ratings\n",
    "    ''')\n",
    "\n",
    "global_mean = global_rating.collect()[0].global_mean\n",
    "global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "different-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     avg_user_rating|\n",
      "+-------+--------------------+\n",
      "|   null|   25127.74193548387|\n",
      "|      1|  0.7428571428571429|\n",
      "|      2|                 1.0|\n",
      "|      3| 0.32786885245901637|\n",
      "|      4|  0.6833333333333333|\n",
      "|      5|  1.2802056555269923|\n",
      "|      6|  1.1612903225806452|\n",
      "|     10|  1.1655266757865936|\n",
      "|     11|0.007194244604316547|\n",
      "|     12| 0.28205128205128205|\n",
      "|     13|                 0.0|\n",
      "|     14|                 0.0|\n",
      "|     15|  2.2901234567901234|\n",
      "|     16|  1.8895348837209303|\n",
      "|     17|                 0.6|\n",
      "|     18|  1.6422764227642277|\n",
      "|     19|  0.5396825396825397|\n",
      "|     24|                 2.0|\n",
      "|     25|                 2.0|\n",
      "|     26|  1.6666666666666667|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_result = spark.sql('''\n",
    "    SELECT user_id, avg(rating) as avg_user_rating\n",
    "    FROM ratings\n",
    "    group by user_id\n",
    "    order by user_id\n",
    "\n",
    "    ''')\n",
    "\n",
    "user_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-skill",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "twenty-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "false-waters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28205128205128205"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n=10\n",
    "user_result.collect()[n-1].avg_user_rating #gives avg user rating for nth user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "placed-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                name|  avg_route_rating|\n",
      "+--------------------+------------------+\n",
      "|                null|0.8990536277602523|\n",
      "|\t Massacre À La T...|               0.0|\n",
      "|          \tDinosaure|               1.0|\n",
      "|    \tEarth to Stella|               1.0|\n",
      "|    \tExpress sumarqu|               3.0|\n",
      "|    \tIndigo Galliace|               3.0|\n",
      "|    \tLa farse tranqu|               2.0|\n",
      "|    \tMove Over Bruss|               0.0|\n",
      "|\tProstowanie wariant|               1.0|\n",
      "|         \tSlip Bouse|               2.0|\n",
      "|          \tSpit Bull|               2.0|\n",
      "|    \tgagae de ma par|               3.0|\n",
      "|    \tpeur aux tafiol|               3.0|\n",
      "|    \tpriez pour nous|               3.0|\n",
      "|              \u001e",
      "\u001e",
      "....|               0.0|\n",
      "| \t Aresta dinamitada|               3.0|\n",
      "| \t Io sto con gli ip|               0.0|\n",
      "| \t Le P'tit Toit ...|               3.0|\n",
      "| \t Unendliche Ges...|               3.0|\n",
      "|      \tAire de Repos|               3.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "route_result = spark.sql('''\n",
    "    SELECT name, AVG(rating) as avg_route_rating\n",
    "    FROM ratings\n",
    "    GROUP BY name\n",
    "    ORDER BY name\n",
    "    ''')\n",
    "\n",
    "route_result.show()\n",
    "# route_result.collect()[n-1].avg_movie_rating #gives avg movie rating for nth movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "conventional-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_result = spark.sql('''\n",
    "    SELECT name, AVG(rating) as avg_route_rating\n",
    "    FROM ratings\n",
    "    GROUP BY name\n",
    "    ORDER BY name\n",
    "    ''')\n",
    "\n",
    "# movie_result.show()\n",
    "route_result = route_result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acting-appendix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>avg_route_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.899054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\t Massacre À La Tronconneuse</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\tDinosaure</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\tEarth to Stella</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\tExpress sumarqu</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886932</th>\n",
       "      <td>�zlem</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886933</th>\n",
       "      <td>���</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886934</th>\n",
       "      <td>🔥 in the Hole</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886935</th>\n",
       "      <td>😀</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886936</th>\n",
       "      <td>😗</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>886937 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  avg_route_rating\n",
       "0                                None          0.899054\n",
       "1       \\t Massacre À La Tronconneuse          0.000000\n",
       "2                         \\tDinosaure          1.000000\n",
       "3                   \\tEarth to Stella          1.000000\n",
       "4                   \\tExpress sumarqu          3.000000\n",
       "...                               ...               ...\n",
       "886932                          �zlem          1.500000\n",
       "886933                            ���          0.000000\n",
       "886934                  🔥 in the Hole          2.000000\n",
       "886935                              😀          0.000000\n",
       "886936                              😗          0.000000\n",
       "\n",
       "[886937 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-allen",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "floral-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, test_df = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cognitive-harvest",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Column name must be of type numeric but was actually of type string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-0846d1c8737b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m als = ALS(rank=4 , maxIter=10 , regParam=0.1 , userCol='user_id', itemCol='name', \\\n\u001b[1;32m      2\u001b[0m           coldStartStrategy='drop', nonnegative = True, ratingCol='rating')\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Column name must be of type numeric but was actually of type string."
     ]
    }
   ],
   "source": [
    "\n",
    "als = ALS(rank=4 , maxIter=10 , regParam=0.1 , userCol='user_id', itemCol='name', \\\n",
    "          coldStartStrategy='drop', nonnegative = True, ratingCol='rating')\n",
    "model = als.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df)\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
    "new_predictions = predictions.filter(predictions.prediction!=np.nan)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs = model.recommendForAllUsers(10)\n",
    "userRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-diabetes",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
